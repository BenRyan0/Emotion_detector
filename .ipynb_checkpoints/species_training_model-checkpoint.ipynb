{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeB10ZMav-SW"
   },
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPw7by-7Fs5M"
   },
   "source": [
    "Dataset Link: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vUbBvinu8zW"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from pandas>=0.25->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benry\\anaconda3\\envs\\tf_new\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4JsejDm3uxTS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2w52yYrvTu9"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU3NlcKCwlIZ"
   },
   "source": [
    "### Training Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kjoa0oUHvQAv",
    "outputId": "35053f0d-5fd0-4b98-cd8f-fa0a88a79e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3208 files belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK9Ev76o0mdJ"
   },
   "source": [
    "### Validation Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tocls4IowkNB",
    "outputId": "3b0d8b3d-8552-4e0f-c1f2-7c9f7e28a944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To avoid Overshooting Loss function\n",
    "1. Choose small learning rate default 0.001 here we have taken 0.0001\n",
    "2. There may be chance of underfitting so increase number of neuron\n",
    "3. Add more Convolutional Layer to extract more feature from images there may be possibilty that model unable to capture relevant feature or model is confusing due to lack of feature so feed with more feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(20, activation='softmax')  # Ensure this matches the number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ_TcbD7r2Cw"
   },
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cUMiJrPvsBTU"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgFWYq7ssLkV"
   },
   "source": [
    "### Building Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LoaODWuZrHFg"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5-potKmKsOr2"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NPZ2NGthuTv5"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "demjWjcWuc3q"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2onuZO6YuBF3"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.4)) #To avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "toAqflkCuwoS"
   },
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYYdAFZDvt1P"
   },
   "source": [
    "### Compiling and Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yAcyiEfVvVzw"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0MROJsdlC5Z",
    "outputId": "59099315-950c-4546-d62d-626f4ca3b80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 63, 63, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 38)                57038     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,842,762\n",
      "Trainable params: 7,842,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3W4dNUrvxIw",
    "outputId": "c4d220dc-40d6-438e-b940-751b3e85b037",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 20) and (None, 38) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer8erj84c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\benry\\anaconda3\\envs\\TF_new\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 20) and (None, 38) are incompatible\n"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19E3mwj1phoW"
   },
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY6o3uxjpgl5",
    "outputId": "372a2b25-5cdd-47c0-da77-1e9a5ee84f6c"
   },
   "outputs": [],
   "source": [
    "#Training set Accuracy\n",
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SaQgd7bpgwl",
    "outputId": "0e82ce04-bdf8-4b31-bc00-cbb7198df7e7"
   },
   "outputs": [],
   "source": [
    "#Validation set Accuracy\n",
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print('Validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qxp0xsjVBGec"
   },
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEUrBzCrxKt_"
   },
   "outputs": [],
   "source": [
    "cnn.save('trained_plant_disease_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('trained_plant_disease_model_IT3A.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_filename = 'trained_plant_disease_model.h5'\n",
    "cnn.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_filename = 'trained_plant_disease_model_IT3A.keras'\n",
    "cnn.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM-sILNMBwh1",
    "outputId": "3d1eb8a8-2742-4b1b-f8f3-10c1f0803975"
   },
   "outputs": [],
   "source": [
    "training_history.history #Return Dictionary of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdF3Ig4ZBU9V"
   },
   "outputs": [],
   "source": [
    "#Recording History in json\n",
    "import json\n",
    "with open('training_hist.json','w') as f:\n",
    "  json.dump(training_history.history,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8PnAYbuCNhu",
    "outputId": "665cd52d-4777-4e7e-9c04-cc7716c5fb62"
   },
   "outputs": [],
   "source": [
    "print(training_history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNIMPXKFEZ5B"
   },
   "source": [
    "## Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "gfKdieuJCt3m",
    "outputId": "00c39bea-d59d-48bd-a9bb-f819e1313252"
   },
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs,training_history.history['accuracy'],color='red',label='Training Accuracy')\n",
    "plt.plot(epochs,training_history.history['val_accuracy'],color='blue',label='Validation Accuracy')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.title('Visualization of Accuracy Result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmHXzT0PAiOn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = validation_set.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(test_set)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categories = tf.concat([y for x, y in test_set], axis=0)\n",
    "Y_true = tf.argmax(true_categories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(Y_true,predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall Fscore\n",
    "print(classification_report(Y_true,predicted_categories,target_names=class_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(cm,annot=True,annot_kws={\"size\": 10})\n",
    "\n",
    "plt.xlabel('Predicted Class',fontsize = 20)\n",
    "plt.ylabel('Actual Class',fontsize = 20)\n",
    "plt.title('Plant Disease Prediction Confusion Matrix',fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
